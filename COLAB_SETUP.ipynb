{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# AI Video Processing Pipeline - Google Colab Setup\n",
        "\n",
        "This notebook sets up and tests the complete video processing pipeline:\n",
        "1. **CodeFormer** - Face restoration\n",
        "2. **LivePortrait** - Portrait animation\n",
        "3. **Real-ESRGAN** - Video upscaling\n",
        "4. **FILM** - Frame interpolation\n",
        "\n",
        "**Note**: Enable GPU in Runtime → Change runtime type → GPU (T4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install system dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "# Install Python packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install tensorflow==2.8.0\n",
        "!pip install numpy==1.26.4\n",
        "!pip install protobuf==3.20.3\n",
        "!pip install opencv-python pillow scipy scikit-image imageio\n",
        "!pip install fastapi uvicorn\n",
        "!pip install basicsr facexlib gfpgan\n",
        "!pip install tensorflow-addons==0.18.0\n",
        "!pip install tensorflow-datasets==4.4.0\n",
        "!pip install apache-beam>=2.43.0,<2.63.0\n",
        "!pip install mediapy absl-py gin-config parameterized natsort gdown tqdm\n",
        "!pip install transformers onnxruntime-gpu\n",
        "!pip install gradio tyro pyyaml\n",
        "\n",
        "print(\"✓ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## Step 2: Clone Repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repos"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "# Clone repositories\n",
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "!git clone https://github.com/KlingTeam/LivePortrait.git\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "!git clone https://github.com/google-research/frame-interpolation.git\n",
        "\n",
        "print(\"✓ Repositories cloned!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## Step 3: Fix Compatibility Issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fix_compat"
      },
      "outputs": [],
      "source": [
        "# Fix basicsr torchvision import (Real-ESRGAN)\n",
        "import re\n",
        "\n",
        "degradations_path = '/content/Real-ESRGAN/realesrgan/data/degradations.py'\n",
        "if os.path.exists(degradations_path):\n",
        "    with open(degradations_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    content = content.replace(\n",
        "        'from torchvision.transforms.functional_tensor import rgb_to_grayscale',\n",
        "        'from torchvision.transforms.functional import rgb_to_grayscale'\n",
        "    )\n",
        "    with open(degradations_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Fixed Real-ESRGAN torchvision import\")\n",
        "\n",
        "# Create version.py files\n",
        "version_files = [\n",
        "    ('/content/Real-ESRGAN/realesrgan/version.py', '0.3.0'),\n",
        "    ('/content/CodeFormer/basicsr/version.py', '1.3.2')\n",
        "]\n",
        "\n",
        "for filepath, version in version_files:\n",
        "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write(f\"\"\"# GENERATED VERSION FILE\n",
        "# TIME: Generated manually\n",
        "__version__ = '{version}'\n",
        "__gitsha__ = 'unknown'\n",
        "version_info = {tuple(map(int, version.split('.')))}\n",
        "\"\"\")\n",
        "    print(f\"✓ Created {filepath}\")\n",
        "\n",
        "# Fix frame-interpolation tf.data.AUTOTUNE\n",
        "data_lib_path = '/content/frame-interpolation/training/data_lib.py'\n",
        "if os.path.exists(data_lib_path):\n",
        "    with open(data_lib_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    content = content.replace('tf.data.experimental.AUTOTUNE', 'tf.data.AUTOTUNE')\n",
        "    with open(data_lib_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Fixed frame-interpolation tf.data.AUTOTUNE\")\n",
        "\n",
        "# Fix Real-ESRGAN video inference CPU handling\n",
        "video_inference_path = '/content/Real-ESRGAN/inference_realesrgan_video.py'\n",
        "if os.path.exists(video_inference_path):\n",
        "    with open(video_inference_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    # Fix num_process for CPU\n",
        "    content = re.sub(\n",
        "        r'num_process = num_gpus \\* args\\.num_process_per_gpu',\n",
        "        r'num_process = max(1, num_gpus * args.num_process_per_gpu)  # Ensure at least 1 process for CPU mode',\n",
        "        content\n",
        "    )\n",
        "    \n",
        "    # Fix CUDA synchronization\n",
        "    content = content.replace(\n",
        "        '        torch.cuda.synchronize(device)',\n",
        "        '        # Only synchronize if using CUDA device\\n        if device is not None and device.type == \\'cuda\\':\\n            torch.cuda.synchronize(device)'\n",
        "    )\n",
        "    \n",
        "    with open(video_inference_path, 'w') as f:\n",
        "        f.write(content)\n",
        "    print(\"✓ Fixed Real-ESRGAN video inference\")\n",
        "\n",
        "print(\"\\n✓ All compatibility fixes applied!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## Step 4: Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_weights"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('/content/pretrained_models', exist_ok=True)\n",
        "os.makedirs('/content/CodeFormer/weights/CodeFormer', exist_ok=True)\n",
        "os.makedirs('/content/Real-ESRGAN/weights', exist_ok=True)\n",
        "\n",
        "print(\"Downloading model weights...\")\n",
        "print(\"This may take a while...\")\n",
        "\n",
        "# CodeFormer weights\n",
        "print(\"\\n[1/4] Downloading CodeFormer weights...\")\n",
        "codeformer_url = 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth'\n",
        "!wget -q {codeformer_url} -O /content/CodeFormer/weights/CodeFormer/codeformer.pth\n",
        "print(\"✓ CodeFormer weights downloaded\")\n",
        "\n",
        "# Real-ESRGAN weights\n",
        "print(\"\\n[2/4] Downloading Real-ESRGAN weights...\")\n",
        "realesrgan_url = 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth'\n",
        "!wget -q {realesrgan_url} -O /content/Real-ESRGAN/weights/RealESRGAN_x4plus.pth\n",
        "print(\"✓ Real-ESRGAN weights downloaded\")\n",
        "\n",
        "# LivePortrait weights (using HuggingFace)\n",
        "print(\"\\n[3/4] Downloading LivePortrait weights from HuggingFace...\")\n",
        "!pip install -q huggingface_hub\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(\n",
        "    repo_id=\"KlingTeam/LivePortrait\",\n",
        "    local_dir=\"/content/LivePortrait/pretrained_weights\",\n",
        "    ignore_patterns=[\"*.git*\", \"README.md\", \"docs\"]\n",
        ")\n",
        "print(\"✓ LivePortrait weights downloaded\")\n",
        "\n",
        "# FILM weights (frame-interpolation)\n",
        "print(\"\\n[4/4] Downloading FILM weights from Google Drive...\")\n",
        "print(\"Note: You may need to download manually from:\")\n",
        "print(\"https://drive.google.com/drive/folders/1q8110-qp225asX3DQvZnfLfJPkCHmDpy?usp=sharing\")\n",
        "print(\"Or use gdown to download the folder...\")\n",
        "\n",
        "# Try using gdown for FILM weights\n",
        "film_folder_id = '1q8110-qp225asX3DQvZnfLfJPkCHmDpy'\n",
        "try:\n",
        "    !gdown --folder https://drive.google.com/drive/folders/{film_folder_id} -O /content/pretrained_models --remaining-ok\n",
        "    print(\"✓ FILM weights downloaded\")\n",
        "except:\n",
        "    print(\"⚠ FILM weights download failed - you may need to download manually\")\n",
        "\n",
        "print(\"\\n✓ Weight download complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## Step 5: Test Individual Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test1"
      },
      "source": [
        "### Test 1: Real-ESRGAN (Image Upscaling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_realesrgan"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/Real-ESRGAN')\n",
        "\n",
        "from inference_realesrgan import main\n",
        "import argparse\n",
        "\n",
        "# Create test image directory\n",
        "os.makedirs('/content/Real-ESRGAN/inputs', exist_ok=True)\n",
        "\n",
        "# Upload a test image or use a sample\n",
        "print(\"Upload a test image to /content/Real-ESRGAN/inputs/ or use the sample below\")\n",
        "\n",
        "# Test with sample (if you have one)\n",
        "# args = argparse.Namespace(\n",
        "#     input='/content/Real-ESRGAN/inputs/test.jpg',\n",
        "#     model_name='RealESRGAN_x4plus',\n",
        "#     output='/content/Real-ESRGAN/results',\n",
        "#     outscale=4,\n",
        "#     suffix='out',\n",
        "#     tile=0,\n",
        "#     tile_pad=10,\n",
        "#     pre_pad=0,\n",
        "#     face_enhance=False,\n",
        "#     fp32=False,\n",
        "#     alpha_upsampler='realesrgan',\n",
        "#     ext='auto'\n",
        "# )\n",
        "# main(args)\n",
        "\n",
        "print(\"Ready to test Real-ESRGAN!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test2"
      },
      "source": [
        "### Test 2: CodeFormer (Face Restoration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_codeformer"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/CodeFormer')\n",
        "\n",
        "os.makedirs('/content/CodeFormer/inputs', exist_ok=True)\n",
        "\n",
        "print(\"Ready to test CodeFormer!\")\n",
        "print(\"Upload test images to /content/CodeFormer/inputs/\")\n",
        "print(\"Then run:\")\n",
        "print(\"!cd /content/CodeFormer && python inference_codeformer.py -w 0.7 --input_path inputs/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test3"
      },
      "source": [
        "### Test 3: Frame Interpolation (FILM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_film"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/frame-interpolation')\n",
        "\n",
        "os.makedirs('/content/frame-interpolation/photos', exist_ok=True)\n",
        "\n",
        "print(\"Ready to test FILM!\")\n",
        "print(\"Upload two test images to /content/frame-interpolation/photos/\")\n",
        "print(\"Then run:\")\n",
        "print(\"!cd /content/frame-interpolation && python3 -m eval.interpolator_test \\\\\")\n",
        "print(\"  --frame1 photos/one.png \\\\\")\n",
        "print(\"  --frame2 photos/two.png \\\\\")\n",
        "print(\"  --model_path /content/pretrained_models/film_net/Style/saved_model \\\\\")\n",
        "print(\"  --output_frame photos/output.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test4"
      },
      "source": [
        "### Test 4: LivePortrait (Portrait Animation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_liveportrait"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/LivePortrait')\n",
        "\n",
        "print(\"Ready to test LivePortrait!\")\n",
        "print(\"Upload source image and driving video, then run:\")\n",
        "print(\"!cd /content/LivePortrait && python inference.py -s path/to/source.jpg -d path/to/driving.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "full_pipeline"
      },
      "source": [
        "## Step 6: Test Full Pipeline (Optional)\n",
        "\n",
        "If you have the pipeline code, you can test the complete workflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_pipeline"
      },
      "outputs": [],
      "source": [
        "# If you upload your pipeline code, you can test it here\n",
        "# from models.pipeline import VideoPipeline\n",
        "# \n",
        "# pipeline = VideoPipeline(device='cuda')\n",
        "# output = pipeline.process_video(\n",
        "#     input_video_path='input.mp4',\n",
        "#     audio_path='audio.wav',\n",
        "#     output_path='output.mp4'\n",
        "# )\n",
        "\n",
        "print(\"Pipeline ready for testing!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notes"
      },
      "source": [
        "## Notes\n",
        "\n",
        "1. **GPU Required**: Enable GPU in Colab (Runtime → Change runtime type → GPU)\n",
        "2. **Storage**: Colab provides ~80GB disk space, but model weights are large (~5-10GB total)\n",
        "3. **Session Timeout**: Colab free tier sessions timeout after ~12 hours of inactivity\n",
        "4. **Download Results**: Use Colab's file browser or download programmatically\n",
        "\n",
        "## Quick Test Commands\n",
        "\n",
        "After setup, test each model:\n",
        "\n",
        "```bash\n",
        "# Real-ESRGAN\n",
        "cd /content/Real-ESRGAN\n",
        "python inference_realesrgan.py -n RealESRGAN_x4plus -i inputs/test.jpg -o results\n",
        "\n",
        "# CodeFormer\n",
        "cd /content/CodeFormer\n",
        "python inference_codeformer.py -w 0.7 --input_path inputs/\n",
        "\n",
        "# FILM\n",
        "cd /content/frame-interpolation\n",
        "python3 -m eval.interpolator_test --frame1 photos/one.png --frame2 photos/two.png --model_path /content/pretrained_models/film_net/Style/saved_model --output_frame photos/output.png\n",
        "\n",
        "# LivePortrait\n",
        "cd /content/LivePortrait\n",
        "python inference.py -s assets/examples/source/s6.jpg -d assets/examples/driving/d0.mp4\n",
        "```"
      ]
    }
  ]
}
